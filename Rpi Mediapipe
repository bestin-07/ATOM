import cv2
import numpy as np
import requests
import mediapipe as mp


url = 'http://192.168.0.3:8080/shot.jpg'

#mp_drawing = mp.solutions.drawing_utils
mp_hands = mp.solutions.hands



# For webcam input:
#cap = cv2.VideoCapture('http://192.168.0.3:8080/video')
hands= mp_hands.Hands(min_detection_confidence=0.5,min_tracking_confidence=0.5)
while True:
    #success, image = cap.read()
    img_resp = requests.get(url)
    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)
    image = cv2.imdecode(img_arr, -1)
    image = cv2.flip(image, 1)
        
    # Flip the image horizontally for a later selfie-view display, and convert
    # the BGR image to RGB.
    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)
    # To improve performance, optionally mark the image as not writeable to
    # pass by reference.
    image.flags.writeable = False
    results = hands.process(image)
        
    # Draw the hand annotations on the image.
    image.flags.writeable = True
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    height = image.shape[0]
    width = image.shape[1]
    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            x1 = int((hand_landmarks.landmark[4].x )* width)
            y1 = int((hand_landmarks.landmark[4].y )* height)
            x2 = int((hand_landmarks.landmark[0].x )* width)
            y2 = int((hand_landmarks.landmark[0].y )* height)
            cv2.line(image, (x1,y1), (x2,y2), (255,0,0), 2)
            print(x1)
            #mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)
    cv2.imshow('MediaPipe Hands', image)
    if cv2.waitKey(5) & 0xFF == 27:
        break
#hands.closed

